{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4897,"status":"ok","timestamp":1691904228211,"user":{"displayName":"王劭宇","userId":"09863575444976027726"},"user_tz":-540},"id":"595F7qXysuCH","outputId":"d669e03e-073f-4594-bf55-dbf5097c90e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/narou\n","all_metadata.csv\t    dimension_reducer_v1.pth  poolformer_v0.ipynb\n","array_reduce.ipynb\t    dimension_reducer_v2.pth  poolformer_v1.ipynb\n","bin_corpus_v1\t\t    encoder_v1.pth\t      poolformer_v2.ipynb\n","corpus-50000-71750.tar.bz2  encoder_v2.pth\t      pth_list.txt\n","corpus_v1\t\t    log.txt\t\t      terminal.ipynb\n","corpus_v2\t\t    ncodes_v1.txt\t      text_binary.ipynb\n","data_v0.5.csv\t\t    ncode_v2.txt\t      VAE.ipynb\n","/content/drive/MyDrive/narou\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/MyDrive/narou\n","!ls -a\n","!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":881,"status":"ok","timestamp":1691904229082,"user":{"displayName":"王劭宇","userId":"09863575444976027726"},"user_tz":-540},"id":"RKzeZ5gkmmWB","outputId":"d55b56a3-d9da-424e-e523-dd11800bd762"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n","Sun Aug 13 05:23:47 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   77C    P0    31W /  70W |   1085MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["import torch\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')\n","\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4004,"status":"ok","timestamp":1691904233079,"user":{"displayName":"王劭宇","userId":"09863575444976027726"},"user_tz":-540},"id":"YGvyOywameOU","outputId":"4519c974-581d-4a60-a12e-d03f2c10c9ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.0)\n"]}],"source":["!pip install tqdm\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5BnRsPAmm8b"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, z_dim=32, in_dim=768):\n","        super().__init__()\n","        self.lr = nn.Linear(in_dim, int(in_dim//2))\n","        self.lr_ave = nn.Linear(int(in_dim//2), z_dim)   #average\n","        self.lr_dev = nn.Linear(int(in_dim//2), z_dim)   #log(sigma^2)\n","        self.relu = nn.ReLU()\n","        self.layer_norm = nn.LayerNorm(in_dim)\n","\n","    def forward(self, x):\n","        x = self.layer_norm(x)\n","        x = self.lr(x)\n","        x = self.relu(x)\n","        ave = self.lr_ave(x)    #average\n","        log_dev = self.lr_dev(x)    #log(sigma^2)\n","\n","        ep = torch.randn_like(ave)   #平均0分散1の正規分布に従い生成されるz_dim次元の乱数\n","        z = ave + torch.exp(log_dev / 2) * ep   #再パラメータ化トリック\n","        return z\n","\n","class Decoder(nn.Module):\n","    def __init__(self, z_dim=32, in_dim=768):\n","        super().__init__()\n","        self.lr = nn.Linear(z_dim, in_dim//2)\n","        self.lr2 = nn.Linear(in_dim//2, in_dim)\n","        self.relu = nn.ReLU()\n","        self.layer_norm = nn.LayerNorm(z_dim)\n","\n","    def forward(self, x):\n","        x = self.layer_norm(x)\n","        x = self.lr(x)\n","        x = self.relu(x)\n","        x = self.lr2(x)\n","\n","\n","        return x\n","\n","class VAE(nn.Module):\n","    def __init__(self, z_dim=32, in_dim=768 ):\n","        super().__init__()\n","        self.encoder = Encoder(z_dim=z_dim, in_dim=in_dim)\n","        self.decoder = Decoder(z_dim=z_dim, in_dim=in_dim)\n","\n","    def forward(self, x):\n","            z = self.encoder(x)\n","            x = self.decoder(z)\n","            return x, z\n"]},{"cell_type":"markdown","metadata":{"id":"Z0E-BrZ6nDf7"},"source":["train"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSnPZmV1mwNj","outputId":"42ce6906-fc3b-405b-d09c-f89cf1f3a3cd","executionInfo":{"status":"ok","timestamp":1691911884208,"user_tz":-540,"elapsed":1700814,"user":{"displayName":"王劭宇","userId":"09863575444976027726"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4234/4234 [2:07:30<00:00,  1.81s/it]\n"]}],"source":["def main(device):\n","\n","    model = torch.load(\"dimension_reducer_v2.pth\").to(device)\n","    corpus = \"/content/drive/MyDrive/narou/bin_corpus_v1/\"\n","    txts = os.listdir(corpus)\n","\n","    model.train()\n","    total_loss_train=0.0\n","    n=0\n","    for txt in tqdm(txts):\n","\n","        input=np.load(corpus+txt)\n","        if input.shape[1] == 768:\n","            pass\n","        else:\n","            continue\n","        torch.cuda.empty_cache()\n","        input=torch.tensor(input[:512*144])\n","        input=torch.unsqueeze(input, 0).to(device)\n","        output, hid=model(input)\n","        #print(f'input:{input}, hid:{hid.shape}, output:{output}')\n","        del output\n","        hid=torch.squeeze(hid, 0)\n","        hid=hid.to('cpu').detach().numpy().copy()\n","        np.save(corpus+txt, hid)\n","\n","\n","if __name__ == \"__main__\":\n","    main(device)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNQ52bREz3J9J09TT4Sd2T5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}